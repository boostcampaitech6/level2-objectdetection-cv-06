{"cells":[{"cell_type":"markdown","metadata":{"id":"4t8WN3ydCHIO"},"source":["# Object Detection - Mission 7\n","#### Ensemble\n","앙상블은 최종 아웃풋의 품질과 가장 직점적으로 연관이 있고, 시간 대비 좋은 결과를 낼 수 있는 방법입니다!\n","지금까지 학습시킨 모델들을 혹은 Sample Submission을 이용해 앙상블 코드를 작성해봅시다.\n","<br>Ensemble의 자세한 내용은 09강: Ready for Competition 강의를 참고합니다."]},{"cell_type":"markdown","metadata":{"id":"e0NRKyCRCjZs"},"source":["## 대회 데이터셋 구성\n","Custom 데이터를 구현하여 대회 데이터셋에 Ensemble 방법을 적용해봅니다. <br>\n","데이터셋의 자세한 개요는 [대회 플랫폼](https://next.stages.ai/competitions/)의 데이터 설명을 참고합니다.\n","> Copyright: CC BY 2.0\n","\n","### dataset\n","    ├── train.json\n","    ├── test.json\n","    ├── train\n","    └── test"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"TL_fCsQ_CFbw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ensemble_boxes\n","  Downloading ensemble_boxes-1.0.9-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy in /Users/baekkwanghyun/miniforge3/envs/torch/lib/python3.10/site-packages (from ensemble_boxes) (1.26.2)\n","Requirement already satisfied: pandas in /Users/baekkwanghyun/miniforge3/envs/torch/lib/python3.10/site-packages (from ensemble_boxes) (1.5.3)\n","Collecting numba (from ensemble_boxes)\n","  Downloading numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n","Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->ensemble_boxes)\n","  Downloading llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /Users/baekkwanghyun/miniforge3/envs/torch/lib/python3.10/site-packages (from pandas->ensemble_boxes) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /Users/baekkwanghyun/miniforge3/envs/torch/lib/python3.10/site-packages (from pandas->ensemble_boxes) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /Users/baekkwanghyun/miniforge3/envs/torch/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->ensemble_boxes) (1.16.0)\n","Downloading numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: llvmlite, numba, ensemble_boxes\n","Successfully installed ensemble_boxes-1.0.9 llvmlite-0.41.1 numba-0.58.1\n"]}],"source":["!pip install ensemble_boxes"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"9gQvhOSxCFb1"},"outputs":[],"source":["import pandas as pd\n","from ensemble_boxes import *\n","import numpy as np\n","from pycocotools.coco import COCO"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"opgAs-9GCFb2"},"outputs":[],"source":["# ensemble csv files\n","submission_files = ['./universe.csv', './cascade_focal.csv', './retina101.csv', './swin_t.csv', './detr.csv', './yolo.csv']\n","submission_df = [pd.read_csv(file, index_col=False) for file in submission_files]"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"GEH0AK1yCFb3"},"outputs":[],"source":["image_ids = submission_df[0]['image_id'].tolist()"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"CrnHsBkGCFb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n"]}],"source":["# ensemble 할 file의 image 정보를 불러오기 위한 json\n","annotation = './test.json'\n","coco = COCO(annotation)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/plain":["[1.3118712273641853,\n"," 1.2327297116029512,\n"," 1.0,\n"," 1.113123183545719,\n"," 1.1066398390342054,\n"," 1.016767270288397]"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["weights = [0.5868, 0.5514, 0.4473, 0.4979, 0.4950, 0.4548]\n","min_value = min(weights)\n","scaled_list = [value / min_value for value in weights]\n","scaled_list"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["6"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["len(scaled_list)"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"bxNjAo3hCFb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 3. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n","Warning: incorrect number of weights 6. Must be: 5. Set weights equal to 1.\n"]}],"source":["prediction_strings = []\n","file_names = []\n","# ensemble 시 설정할 iou threshold 이 부분을 바꿔가며 대회 metric에 알맞게 적용해봐요!\n","iou_thr = 0.6\n","skip_box_thr = 0.001\n","weights = scaled_list\n","\n","# 각 image id 별로 submission file에서 box좌표 추출\n","for i, image_id in enumerate(image_ids):\n","    prediction_string = ''\n","    boxes_list = []\n","    scores_list = []\n","    labels_list = []\n","    image_info = coco.loadImgs(i)[0]\n","#     각 submission file 별로 prediction box좌표 불러오기\n","    for df in submission_df:\n","        predict_string = df[df['image_id'] == image_id]['PredictionString'].tolist()[0]\n","        predict_list = str(predict_string).split()\n","\n","        if len(predict_list)==0 or len(predict_list)==1:\n","            continue\n","\n","        predict_list = np.reshape(predict_list, (-1, 6))\n","        box_list = []\n","\n","        for box in predict_list[:, 2:6].tolist():\n","            box[0] = float(box[0]) / image_info['width']\n","            box[1] = float(box[1]) / image_info['height']\n","            box[2] = float(box[2]) / image_info['width']\n","            box[3] = float(box[3]) / image_info['height']\n","            box_list.append(box)\n","\n","        boxes_list.append(box_list)\n","        scores_list.append(list(map(float, predict_list[:, 1].tolist())))\n","        labels_list.append(list(map(int, predict_list[:, 0].tolist())))\n","        \n","\n","#     예측 box가 있다면 이를 ensemble 수행\n","    if len(boxes_list):\n","        boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=scaled_list, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","        for box, score, label in zip(boxes, scores, labels):\n","            prediction_string += str(int(label)) + ' ' + str(score) + ' ' + str(box[0] * image_info['width']) + ' ' + str(box[1] * image_info['height']) + ' ' + str(box[2] * image_info['width']) + ' ' + str(box[3] * image_info['height']) + ' '\n","\n","    prediction_strings.append(prediction_string)\n","    file_names.append(image_id)"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"K1QwofbNCFb5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PredictionString</th>\n","      <th>image_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7 0.9758523728560446 603.2963256835938 515.428...</td>\n","      <td>test/0000.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5 0.7109988580494588 133.72361755371094 0.3450...</td>\n","      <td>test/0001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1 0.8299846370247225 295.8479919433594 316.513...</td>\n","      <td>test/0002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9 0.5527059433879347 125.22518920898438 253.94...</td>\n","      <td>test/0003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0 0.3793897142860516 426.0456848144531 408.948...</td>\n","      <td>test/0004.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    PredictionString       image_id\n","0  7 0.9758523728560446 603.2963256835938 515.428...  test/0000.jpg\n","1  5 0.7109988580494588 133.72361755371094 0.3450...  test/0001.jpg\n","2  1 0.8299846370247225 295.8479919433594 316.513...  test/0002.jpg\n","3  9 0.5527059433879347 125.22518920898438 253.94...  test/0003.jpg\n","4  0 0.3793897142860516 426.0456848144531 408.948...  test/0004.jpg"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["submission = pd.DataFrame()\n","submission['PredictionString'] = prediction_strings\n","submission['image_id'] = file_names\n","submission.to_csv('./ensemble9.csv', index=False)\n","\n","submission.head()"]},{"cell_type":"markdown","metadata":{"id":"pj76TIByCsPr"},"source":["### Reference\n","https://github.com/ZFTurbo/Weighted-Boxes-Fusion"]},{"cell_type":"markdown","metadata":{"id":"VFJDriTsCFb6"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
